#' Evaluate univariate continuous predictions over a validation set for a given score function.
#' 
#' @details Given a \code{datasetResample} object and a compatible 
#' \code{uniContValidation} prediction object it computes prediction scores
#' of some \code{type} for each model used in the validation step. 
#' 
#' @param pred_obj A \code{uniContValidation} object, usually generated
#'  from the \code{datasetResample} object with
#'  some set of predictive models through an interface function to 
#'  the \code{tgmUniCont} package.
#' @param resample_indexes A \code{datasetResample} object, usually
#'  generated by the \code{generateTestIndexes} function.
#' @param type Which type of score function should be used. 
#'  See \code{?computeUniContScore} for the updated list of score 
#'  functions available.
#' @param ignore_tag Before computing scores, we check to see if 
#'  \code{pred_obj} was indeed generated from the \code{resample_indexes}.
#'  In case of a mismatch an error is issued, unless \code{ignore_tag = FALSE},
#'  in which case just a warning is issued.
#' 
#' @return An S3 object of class \code{multiClassValidationScores}.
#' 
#' @export
evaluateProbClass.uniContValidation <- function(pred_obj, resample_indexes, type, 
                                                ignore_tag = FALSE, replicate_index = NULL, ...){
  
  resample_tag <- mcGet(resample_indexes, "tag")
  prediction_tag <- mcGet(pred_obj, "tag")
  
  checkTags(resample_tag = resample_tag, 
            prediction_tag = prediction_tag, 
            ignore_tag = ignore_tag)
  
  number_models <- mcGet(pred_obj, "number_models")
  scores_all <- list()
  
  weight_name <- mcGet(pred_obj, "weight_name")
  if (is.null(weight_name)){
    weight <- NULL
  } else {
    weight <- mcGet(resample_indexes, "dataset")
    weight <- weight[mcGet(resample_indexes, "validation", i = replicate_index), weight_name]
  }

  target_i <- mcGet(resample_indexes, "validation_target", i = replicate_index)
  
  for (i in 1:number_models){
    
    predictions_i <- mcGet(pred_obj, "pred", i)
    scores_all[[i]] <- computeUniContScore(prediction = predictions_i, target = target_i, type = type, weight = weight, ...)
    
  }
  
  ## The class multiClassValidationScores seems to be suited for 
  ## uniContValidation as well. Later change it for a more general name.
  result <- multiClassValidationScores(scores_list = scores_all, 
                                       resample_indexes = resample_indexes, 
                                       replicate_index = replicate_index, 
                                       score_type = type,
                                       tune_grid = mcGet(pred_obj, "tune_grid"))
  return(result)
  
}

#' Evaluate univariate continuous predictions for a given score function.
#' 
#' @details Given a \code{datasetResample} object and a compatible 
#' \code{uniCont} prediction object it computes prediction scores
#' of some \code{type} for each replication. 
#' 
#' @param pred_obj A \code{uniCont} object, usually generated
#'  from the \code{datasetResample} object with
#'  some predictive model with an interface function to 
#'  the \code{tgmUniCont} package.
#' @param resample_indexes A \code{datasetResample} object, usually
#'  generated by the \code{generateTestIndexes} function.
#' @param type Which type of score function should be used. 
#'  See \code{?computeUniContScore} for the updated list of score 
#'  functions available.
#' @param ignore_tag Before computing scores, we check to see if 
#'  \code{pred_obj} was indeed generated from the \code{resample_indexes}.
#'  In case of a mismatch an error is issued, unless \code{ignore_tag = FALSE},
#'  in which case just a warning is issued.
#' 
#' @return An S3 object of class \code{multiClassScores}.
#' 
#' @export
evaluateProbClass.uniCont <- function(pred_obj, resample_indexes, type, ignore_tag = FALSE, ...){
  
  resample_tag <- mcGet(resample_indexes, "tag")
  prediction_tag <- mcGet(pred_obj, "tag")
  
  checkTags(resample_tag = resample_tag, 
            prediction_tag = prediction_tag, 
            ignore_tag = ignore_tag)
  
  number_replicates <- mcGet(resample_indexes, "number_replicates")
  scores_all <- list()
  
  
  
  for (i in 1:number_replicates){

    weight_name <- mcGet(pred_obj, "weight_name")
    if (is.null(weight_name)){
      weight <- NULL
    } else {
      weight <- mcGet(resample_indexes, "dataset")
      weight <- weight[mcGet(resample_indexes, "test", i = i), weight_name]
    }
    
    predictions_i <- mcGet(pred_obj, "pred", i)
    target_i <- mcGet(resample_indexes, "test_target", i)
    scores_all[[i]] <- computeUniContScore(prediction = predictions_i, target = target_i, type = type, weight = weight, ...)
    
  }
  
  ## The class multiClassScores seems to be suited for 
  ## uniCont as well. Later change it for a more general name.
  result <- multiClassScores(scores_list = scores_all, 
                             resample_indexes = resample_indexes, 
                             score_type = type)
  return(result)
  
}

#' Compute scores from univariate and continuous predictions.
#' 
#' @details Given a set of \code{prediction} and \code{target} values it will
#'   compute the score function for each prediction point. Possibly each prediction
#'   point can be associated with a \code{weight}
#'   
#' @param prediction Numeric vector with univariate predictions.
#' @param target Numeric vector with the observed values of the target variables.
#' @param type Which score function to use. See details.
#' @param weight Numeric vector with the weight given to each prediction point. 
#'  Default is NULL.
#' @param ... extra parameters used in a specific score function. Currently not in use.
#' 
#' @details Currently available score functions are 'negative_square_error'.
#'   
#' @return Numeric vector with length equal to the number of \code{prediction}
#' points containing the scores for each prediction point.
#' 
#' @export       
computeUniContScore <- function(prediction, target, type, weight = NULL, ...){
  
  if (type == "negative_square_error"){
    result <- computeNegativeSquareError(prediction = prediction, target = target, weight = weight)
    return(result)
  } else if (type == "negative_absolute_error"){
    result <- computeNegativeAbsoluteError(prediction = prediction, target = target, weight = weight)
    return(result)
  } else {
    stop("Invalid type.\n")
  }
  
}

#' Compute the negative of the square error of predictions
#' 
#' Compute the negative of the square error of predictions. The negative part
#' is to ensure that the higher the metric is the better.
#' 
#' @param prediction Numeric vector with univariate predictions.
#' @param target Numeric vector with the observed values of the target variables.
#' @param weight Numeric vector with the weight given to each prediction point. 
#'  Default is NULL.
#'  
#' @export
computeNegativeSquareError <- function(prediction, target, weight = NULL){
  
  if (is.null(weight)){
    result <- - as.numeric((prediction - target)^2)
    return(result)
  } else {
    result <- - as.numeric(weight*((prediction - target)^2))
    return(result)
  }
  
}

#' Compute the negative of the absolute error of predictions
#' 
#' Compute the negative of the absolute error of predictions. The negative part
#' is to ensure that the higher the metric is the better.
#' 
#' @param prediction Numeric vector with univariate predictions.
#' @param target Numeric vector with the observed values of the target variables.
#' @param weight Numeric vector with the weight given to each prediction point. 
#'  Default is NULL.
#'  
#' @export
computeNegativeAbsoluteError <- function(prediction, target, weight = NULL){
  
  if (is.null(weight)){
    result <- - as.numeric(abs(prediction - target))
    return(result)
  } else {
    result <- - as.numeric(weight*(abs(prediction - target)))
    return(result)
  }
  
}

## Transform the function below into a method. We have an equivalent one for multiClass

#' Build calibration plots for a \code{uniCont} object
#' 
#' @export
checkCalibration_uniCont <- function(fitted_model, resample_indexes, number_bins, 
                                     weight_lower_bound = NULL, x_axis = "predicted"){
  
  if (!(inherits(fitted_model, "uniCont") & 
          inherits(resample_indexes, "datasetResample"))){
    stop("'fitted_model' needs to be a 'uniCont' object and 'resample_indexes' needs to be a 'datasetResample'")
  }
  
  if (!require(ggplot2)) stop("Please, install ggplot2.")
  if (!require(MASS)) stop("Please, install MASS.")
  if (!require(splines)) stop("Please, install splines.")
  
  number_replicates <- mcGet(fitted_model, "number_replicates")
  
  joint_pred_probs <- NULL
  joint_target <- NULL
  for (i in 1:number_replicates){ 
    joint_pred_probs <- c(joint_pred_probs, mcGet(fitted_model, "pred", i))
    joint_target <- c(joint_target, mcGet(resample_indexes, "test_target", i))
  }
  
  if (!is.null(weight_lower_bound)){
    
    weight_name <- mcGet(fitted_model, "weight_name")
    joint_weights <- NULL
    for (i in 1:number_replicates){ 
      test_index <- mcGet(resample_indexes, "test", i)
      weights_i <- as.numeric(mcGet(resample_indexes, "dataset", i)[test_index, weight_name])
      joint_weights <- c(joint_weights, weights_i)
    }
    
    temp <- data.frame(joint_pred_probs = joint_pred_probs,
                       joint_target = joint_target,
                       joint_weights = joint_weights)
    
    temp <- subset(temp, joint_weights >= weight_lower_bound)
    joint_pred_probs <- temp[, "joint_pred_probs"]
    joint_target <- temp[, "joint_target"]
    rm(temp)
  }
  
  if (x_axis == "predicted"){

    cuts <- quantile(x = joint_pred_probs, probs = seq(0, 1, length.out = number_bins + 1))
    pred_prob_bins <- cut(joint_pred_probs, breaks = unique(cuts))
    pred_points <- tapply(joint_pred_probs, pred_prob_bins, mean, na.rm=TRUE)
    
    bin_sums <- tapply(joint_target, pred_prob_bins, mean, na.rm=TRUE)
    
    calibration_objects <- data.frame(x = pred_points, 
                                      y = bin_sums)  
    x_labs <- "Predicted"
    y_labs <- "Observed"
    
    data_to_plot <- data.frame(x = joint_pred_probs, y = joint_target)
    
  } else if (x_axis == "observed"){
    
    cuts <- quantile(x = joint_target, probs = seq(0, 1, length.out = number_bins + 1))
    target_bins <- cut(joint_target, breaks = unique(cuts))
    target_points <- tapply(joint_target, target_bins, mean, na.rm=TRUE)
    
    bin_sums <- tapply(joint_pred_probs, target_bins, mean, na.rm=TRUE)
    
    calibration_objects <- data.frame(x = target_points, 
                                      y = bin_sums)  
    x_labs <- "Observed"
    y_labs <- "Predicted"
    
    data_to_plot <- data.frame(x = joint_target, y = joint_pred_probs)
    
  }

  plot_calibration_points <- ggplot(calibration_objects) + 
    geom_point(aes(x = x, y = y)) + 
    labs(x = x_labs, y = y_labs) +
    geom_abline(intercept = 0, slope = 1)
  
  plot_smooth_calibration <- ggplot(data_to_plot, aes(x = x, y = y)) + 
    stat_smooth(method = "lm", formula = y ~ ns(x, 3)) + 
    xlim(range(calibration_objects[, "x"], na.rm = TRUE)) +
    geom_abline(intercept = 0, slope = 1) +
    geom_point(data = calibration_objects, mapping = aes(x = x, y)) + 
    labs(x = x_labs, y = y_labs)
  
  result <- list(calibration_objects = calibration_objects,
                 target_name = mcGet(resample_indexes, "target_name"),
                 plot_calibration_points = plot_calibration_points,
                 plot_smooth_calibration = plot_smooth_calibration)
  class(result) <- "uniCont_calibration"
  
  return(result)
  
}

# re-write checkCalibration_uniCont using the function below.

#' Build calibration plots.
#' 
#' @export
checkCalibrationBase <- function(x, y, number_bins, x_labs, y_labs){

  if (!require(ggplot2)) stop("Please, install ggplot2.")
  if (!require(MASS)) stop("Please, install MASS.")
  if (!require(splines)) stop("Please, install splines.")
  
  cuts <- quantile(x = x, probs = seq(0, 1, length.out = number_bins + 1))
  x_bins <- cut(x, breaks = unique(cuts))
  x_points <- tapply(x, x_bins, mean, na.rm=TRUE)
  
  bin_sums <- tapply(y, x_bins, mean, na.rm=TRUE)
  
  calibration_objects <- data.frame(x = x_points, 
                                    y = bin_sums)  
  
  data_to_plot <- data.frame(x = x, y = y)
  
  plot_calibration_points <- ggplot(calibration_objects) + 
    geom_point(aes(x = x, y = y)) + 
    labs(x = x_labs, y = y_labs) +
    geom_abline(intercept = 0, slope = 1)
  
  plot_smooth_calibration <- ggplot(data_to_plot, aes(x = x, y = y)) + 
    stat_smooth(method = "lm", formula = y ~ ns(x, 3)) + 
    xlim(range(calibration_objects[, "x"], na.rm = TRUE)) +
    geom_abline(intercept = 0, slope = 1) +
    geom_point(data = calibration_objects, mapping = aes(x = x, y)) + 
    labs(x = x_labs, y = y_labs)
  
  result <- list(calibration_objects = calibration_objects,
                 plot_calibration_points = plot_calibration_points,
                 plot_smooth_calibration = plot_smooth_calibration)
  
  return(result)
  
}